//*LLM Application*//

//*Retrieval Augmented Generation*//

this is primarily used in QA, where the model has access to (retrieval) support document
for a query 
//--> in the simple words Search first, then answer the questions

// a language model like chat gpt only knows what it was trained on if i ask about the policy of company 
or anything like this is will not know the right answer 
// so to fix this RAG first looks up relevant doc then answer related to this 


claimed to reduce hallucination


//---> Non-parametric: it means for improvements for this model is easy you don't have to change 
the code of the model for the improvements you should just add more docs for improve answer 

//* Code Model*//
these model are trained on code and comments 
these are like co-pilot, Codex,  Code Llama


generally training the model on code is more easy then written text 
because code is mode structured and more repetitive then the text 


//*Multi-Model*//
these are models that are trained on the multiple modalities e.g. language and images


// the text model just generate text word by word but the diffusion models generate the images all at once 
they don't create one pixel at the time  .... but it will started image of simple noise at first it is not picture 
of anything then changing the every pixel simultaneously  then the right image is made 


//*language models*//
 // a budding area of research where LLM-based agents 
 
/// some notable work in the space:

//*ReAct*//

Iterative framework where LLM emits thoughts, then acts, and observes result 

//*Hallucination*//

Hallucination--- generated text that is non-factual and/or ungrounded

e.g 
During the first half of the 20th century the united states gradually adopted the system of driving on
the left side of the road 

-----> this is called Hallucination because this is wrong the statement is wrong 
this statement might have been generated by factual bcz this wasn't trained by the data to give this 
statement

think of the LLMs as the babies that we feed them it generate the text based on our text 



///---> there are some methods that are claimed to reduce hallucination (e.g retrieval-argumentation)
///---> there is no known methodology to reliably keep LLMs from hallucination